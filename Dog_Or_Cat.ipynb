{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhrGOSC1nShc",
        "outputId": "c27e1b25-a06d-4d73-dcb1-c2bcc3dcd84a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/tongpython/cat-and-dog/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "cat_data = [];\n",
        "for filenames in os.walk(path + '/training_set/training_set/cats/'):\n",
        "  for cats in filenames:\n",
        "    for cat in cats:\n",
        "        img = cv2.imread(path + '/training_set/training_set/cats/' + cat)\n",
        "        if img is not None:\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "          img = cv2.resize(img, (100,100))\n",
        "          img = np.expand_dims(img, axis=-1)\n",
        "          img = img / 255.0\n",
        "          cat_data.append(img)\n",
        "\n",
        "dog_data = [];\n",
        "for filenames in os.walk(path + '/training_set/training_set/dogs/'):\n",
        "  for dogs in filenames:\n",
        "    for dog in dogs:\n",
        "        img = cv2.imread(path + '/training_set/training_set/dogs/' + dog)\n",
        "        if img is not None:\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "          img = cv2.resize(img, (100,100))\n",
        "          img = np.expand_dims(img, axis=-1)\n",
        "          img = img / 255.0\n",
        "          dog_data.append(img)\n",
        "\n",
        "print('test cat :' + str(len(cat_data)))\n",
        "print('test dog :' + str(len(dog_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQlb_iZrnnSM",
        "outputId": "c2cd62be-5706-4e11-b53f-04b3f26fd1d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test cat :4000\n",
            "test dog :4005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    # First convolutional layer\n",
        "    model.add(Conv2D(16, (6, 6), activation='relu', input_shape=(100, 100, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Pooling layer to reduce spatial dimensions\n",
        "\n",
        "    # Second convolutional layer\n",
        "    model.add(Conv2D(32, (6, 6), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Pooling layer to reduce spatial dimensions\n",
        "\n",
        "    model.add(Flatten())  # Flatten the output for the Dense layer\n",
        "    model.add(Dense(100, activation='relu'))  # Fully connected layer\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "mtcrnOf2swtm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat = np.zeros(len(cat_data))\n",
        "y_dog = np.ones(len(dog_data))\n",
        "\n",
        "X_train = np.concatenate((cat_data, dog_data), axis=0)  # Shape: (num_samples, 32, 32, 1)\n",
        "y_train = np.concatenate((y_cat, y_dog), axis=0)  # Shape: (num_samples,)\n",
        "\n",
        "# Shuffle the dataset and labels\n",
        "indices = np.arange(X_train.shape[0])  # Create an array of indices\n",
        "print(indices)\n",
        "np.random.shuffle(indices)  # Shuffle the indices\n",
        "print(indices)\n",
        "# Use the shuffled indices to shuffle the data and labels\n",
        "X_train = X_train[indices]\n",
        "y_train = y_train[indices]\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuDEXsdouddh",
        "outputId": "1a85f3e9-0ae6-4b4b-fe1b-55e7a6f0ad86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 8002 8003 8004]\n",
            "[5142  444  940 ... 1008 2321 2130]\n",
            "[1. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_or_dog = create_model()\n",
        "cat_or_dog.fit(X_train, y_train, epochs=15)\n",
        "cat_or_dog.save('cat_or_dog.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdd_eShzplXB",
        "outputId": "109966a8-2565-4f1b-9080-7c556d546550"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.5216 - loss: 0.7099\n",
            "Epoch 2/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6225 - loss: 0.6561\n",
            "Epoch 3/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6787 - loss: 0.6012\n",
            "Epoch 4/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7561 - loss: 0.5154\n",
            "Epoch 5/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8075 - loss: 0.4289\n",
            "Epoch 6/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.3785\n",
            "Epoch 7/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8881 - loss: 0.2802\n",
            "Epoch 8/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.2231\n",
            "Epoch 9/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1552\n",
            "Epoch 10/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1173\n",
            "Epoch 11/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 0.1003\n",
            "Epoch 12/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.0856\n",
            "Epoch 13/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.0753\n",
            "Epoch 14/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0583\n",
            "Epoch 15/15\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"samuelcortinhas/cats-and-dogs-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "test_cat = [];\n",
        "for filenames in os.walk(path + '/train/cats/'):\n",
        "    for file in filenames:\n",
        "      for cat in file:\n",
        "        img = cv2.imread(path + '/train/cats/' + cat)\n",
        "        if img is not None:\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "          img = cv2.resize(img, (100,100))\n",
        "          img = np.expand_dims(img, axis=-1)\n",
        "          img = img / 255.0\n",
        "          test_cat.append(img)\n",
        "\n",
        "test_dog = [];\n",
        "for filenames in os.walk(path + '/train/dogs/'):\n",
        "    for file in filenames:\n",
        "      for dog in file:\n",
        "        img = cv2.imread(path + '/train/dogs/' + dog)\n",
        "        if img is not None:\n",
        "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "          img = cv2.resize(img,( 100,100))\n",
        "          img = np.expand_dims(img, axis=-1)\n",
        "          img = img / 255.0\n",
        "          test_dog.append(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiyHfBZ_ygx0",
        "outputId": "a9596400-3055-4b60-cfa8-f60cf5b85395"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/samuelcortinhas/cats-and-dogs-image-classification?dataset_version_number=4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64.4M/64.4M [00:00<00:00, 91.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/samuelcortinhas/cats-and-dogs-image-classification/versions/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = cat_or_dog.predict(test_dog[1].reshape(1, 100, 100, 1))\n",
        "if(predictions[0]*100 > 50):\n",
        "  print('dog')\n",
        "else:\n",
        "  print('cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L7ZcFcI5ack",
        "outputId": "c6355879-e7fd-4243-cfb3-e9eddb87680b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btyh0OHH5OVf"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}
